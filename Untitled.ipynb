{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c0d4922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e00f452",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data.csv',encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74518124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>Top1</th>\n",
       "      <th>Top2</th>\n",
       "      <th>Top3</th>\n",
       "      <th>Top4</th>\n",
       "      <th>Top5</th>\n",
       "      <th>Top6</th>\n",
       "      <th>Top7</th>\n",
       "      <th>Top8</th>\n",
       "      <th>...</th>\n",
       "      <th>Top16</th>\n",
       "      <th>Top17</th>\n",
       "      <th>Top18</th>\n",
       "      <th>Top19</th>\n",
       "      <th>Top20</th>\n",
       "      <th>Top21</th>\n",
       "      <th>Top22</th>\n",
       "      <th>Top23</th>\n",
       "      <th>Top24</th>\n",
       "      <th>Top25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>A 'hindrance to operations': extracts from the...</td>\n",
       "      <td>Scorecard</td>\n",
       "      <td>Hughes' instant hit buoys Blues</td>\n",
       "      <td>Jack gets his skates on at ice-cold Alex</td>\n",
       "      <td>Chaos as Maracana builds up for United</td>\n",
       "      <td>Depleted Leicester prevail as Elliott spoils E...</td>\n",
       "      <td>Hungry Spurs sense rich pickings</td>\n",
       "      <td>Gunners so wide of an easy target</td>\n",
       "      <td>...</td>\n",
       "      <td>Flintoff injury piles on woe for England</td>\n",
       "      <td>Hunters threaten Jospin with new battle of the...</td>\n",
       "      <td>Kohl's successor drawn into scandal</td>\n",
       "      <td>The difference between men and women</td>\n",
       "      <td>Sara Denver, nurse turned solicitor</td>\n",
       "      <td>Diana's landmine crusade put Tories in a panic</td>\n",
       "      <td>Yeltsin's resignation caught opposition flat-f...</td>\n",
       "      <td>Russian roulette</td>\n",
       "      <td>Sold out</td>\n",
       "      <td>Recovering a title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>0</td>\n",
       "      <td>Scorecard</td>\n",
       "      <td>The best lake scene</td>\n",
       "      <td>Leader: German sleaze inquiry</td>\n",
       "      <td>Cheerio, boyo</td>\n",
       "      <td>The main recommendations</td>\n",
       "      <td>Has Cubie killed fees?</td>\n",
       "      <td>Has Cubie killed fees?</td>\n",
       "      <td>Has Cubie killed fees?</td>\n",
       "      <td>...</td>\n",
       "      <td>On the critical list</td>\n",
       "      <td>The timing of their lives</td>\n",
       "      <td>Dear doctor</td>\n",
       "      <td>Irish court halts IRA man's extradition to Nor...</td>\n",
       "      <td>Burundi peace initiative fades after rebels re...</td>\n",
       "      <td>PE points the way forward to the ECB</td>\n",
       "      <td>Campaigners keep up pressure on Nazi war crime...</td>\n",
       "      <td>Jane Ratcliffe</td>\n",
       "      <td>Yet more things you wouldn't know without the ...</td>\n",
       "      <td>Millennium bug fails to bite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>0</td>\n",
       "      <td>Coventry caught on counter by Flo</td>\n",
       "      <td>United's rivals on the road to Rio</td>\n",
       "      <td>Thatcher issues defence before trial by video</td>\n",
       "      <td>Police help Smith lay down the law at Everton</td>\n",
       "      <td>Tale of Trautmann bears two more retellings</td>\n",
       "      <td>England on the rack</td>\n",
       "      <td>Pakistan retaliate with call for video of Walsh</td>\n",
       "      <td>Cullinan continues his Cape monopoly</td>\n",
       "      <td>...</td>\n",
       "      <td>South Melbourne (Australia)</td>\n",
       "      <td>Necaxa (Mexico)</td>\n",
       "      <td>Real Madrid (Spain)</td>\n",
       "      <td>Raja Casablanca (Morocco)</td>\n",
       "      <td>Corinthians (Brazil)</td>\n",
       "      <td>Tony's pet project</td>\n",
       "      <td>Al Nassr (Saudi Arabia)</td>\n",
       "      <td>Ideal Holmes show</td>\n",
       "      <td>Pinochet leaves hospital after tests</td>\n",
       "      <td>Useful links</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilgrim knows how to progress</td>\n",
       "      <td>Thatcher facing ban</td>\n",
       "      <td>McIlroy calls for Irish fighting spirit</td>\n",
       "      <td>Leicester bin stadium blueprint</td>\n",
       "      <td>United braced for Mexican wave</td>\n",
       "      <td>Auntie back in fashion, even if the dress look...</td>\n",
       "      <td>Shoaib appeal goes to the top</td>\n",
       "      <td>Hussain hurt by 'shambles' but lays blame on e...</td>\n",
       "      <td>...</td>\n",
       "      <td>Putin admits Yeltsin quit to give him a head s...</td>\n",
       "      <td>BBC worst hit as digital TV begins to bite</td>\n",
       "      <td>How much can you pay for...</td>\n",
       "      <td>Christmas glitches</td>\n",
       "      <td>Upending a table, Chopping a line and Scoring ...</td>\n",
       "      <td>Scientific evidence 'unreliable', defence claims</td>\n",
       "      <td>Fusco wins judicial review in extradition case</td>\n",
       "      <td>Rebels thwart Russian advance</td>\n",
       "      <td>Blair orders shake-up of failing NHS</td>\n",
       "      <td>Lessons of law's hard heart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>1</td>\n",
       "      <td>Hitches and Horlocks</td>\n",
       "      <td>Beckham off but United survive</td>\n",
       "      <td>Breast cancer screening</td>\n",
       "      <td>Alan Parker</td>\n",
       "      <td>Guardian readers: are you all whingers?</td>\n",
       "      <td>Hollywood Beyond</td>\n",
       "      <td>Ashes and diamonds</td>\n",
       "      <td>Whingers - a formidable minority</td>\n",
       "      <td>...</td>\n",
       "      <td>Most everywhere:  UDIs</td>\n",
       "      <td>Most wanted:  Chloe lunettes</td>\n",
       "      <td>Return of the cane 'completely off the agenda'</td>\n",
       "      <td>From Sleepy Hollow to Greeneland</td>\n",
       "      <td>Blunkett outlines vision for over 11s</td>\n",
       "      <td>Embattled Dobson attacks 'play now, pay later'...</td>\n",
       "      <td>Doom and the Dome</td>\n",
       "      <td>What is the north-south divide?</td>\n",
       "      <td>Aitken released from jail</td>\n",
       "      <td>Gone aloft</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Label                                               Top1  \\\n",
       "0  2000-01-03      0  A 'hindrance to operations': extracts from the...   \n",
       "1  2000-01-04      0                                          Scorecard   \n",
       "2  2000-01-05      0                  Coventry caught on counter by Flo   \n",
       "3  2000-01-06      1                      Pilgrim knows how to progress   \n",
       "4  2000-01-07      1                               Hitches and Horlocks   \n",
       "\n",
       "                                 Top2  \\\n",
       "0                           Scorecard   \n",
       "1                 The best lake scene   \n",
       "2  United's rivals on the road to Rio   \n",
       "3                 Thatcher facing ban   \n",
       "4      Beckham off but United survive   \n",
       "\n",
       "                                            Top3  \\\n",
       "0                Hughes' instant hit buoys Blues   \n",
       "1                  Leader: German sleaze inquiry   \n",
       "2  Thatcher issues defence before trial by video   \n",
       "3        McIlroy calls for Irish fighting spirit   \n",
       "4                        Breast cancer screening   \n",
       "\n",
       "                                            Top4  \\\n",
       "0       Jack gets his skates on at ice-cold Alex   \n",
       "1                                  Cheerio, boyo   \n",
       "2  Police help Smith lay down the law at Everton   \n",
       "3                Leicester bin stadium blueprint   \n",
       "4                                    Alan Parker   \n",
       "\n",
       "                                          Top5  \\\n",
       "0       Chaos as Maracana builds up for United   \n",
       "1                     The main recommendations   \n",
       "2  Tale of Trautmann bears two more retellings   \n",
       "3               United braced for Mexican wave   \n",
       "4      Guardian readers: are you all whingers?   \n",
       "\n",
       "                                                Top6  \\\n",
       "0  Depleted Leicester prevail as Elliott spoils E...   \n",
       "1                             Has Cubie killed fees?   \n",
       "2                                England on the rack   \n",
       "3  Auntie back in fashion, even if the dress look...   \n",
       "4                                   Hollywood Beyond   \n",
       "\n",
       "                                              Top7  \\\n",
       "0                 Hungry Spurs sense rich pickings   \n",
       "1                           Has Cubie killed fees?   \n",
       "2  Pakistan retaliate with call for video of Walsh   \n",
       "3                    Shoaib appeal goes to the top   \n",
       "4                               Ashes and diamonds   \n",
       "\n",
       "                                                Top8  ...  \\\n",
       "0                  Gunners so wide of an easy target  ...   \n",
       "1                             Has Cubie killed fees?  ...   \n",
       "2               Cullinan continues his Cape monopoly  ...   \n",
       "3  Hussain hurt by 'shambles' but lays blame on e...  ...   \n",
       "4                   Whingers - a formidable minority  ...   \n",
       "\n",
       "                                               Top16  \\\n",
       "0           Flintoff injury piles on woe for England   \n",
       "1                               On the critical list   \n",
       "2                        South Melbourne (Australia)   \n",
       "3  Putin admits Yeltsin quit to give him a head s...   \n",
       "4                             Most everywhere:  UDIs   \n",
       "\n",
       "                                               Top17  \\\n",
       "0  Hunters threaten Jospin with new battle of the...   \n",
       "1                          The timing of their lives   \n",
       "2                                    Necaxa (Mexico)   \n",
       "3         BBC worst hit as digital TV begins to bite   \n",
       "4                       Most wanted:  Chloe lunettes   \n",
       "\n",
       "                                            Top18  \\\n",
       "0             Kohl's successor drawn into scandal   \n",
       "1                                     Dear doctor   \n",
       "2                             Real Madrid (Spain)   \n",
       "3                     How much can you pay for...   \n",
       "4  Return of the cane 'completely off the agenda'   \n",
       "\n",
       "                                               Top19  \\\n",
       "0               The difference between men and women   \n",
       "1  Irish court halts IRA man's extradition to Nor...   \n",
       "2                          Raja Casablanca (Morocco)   \n",
       "3                                 Christmas glitches   \n",
       "4                   From Sleepy Hollow to Greeneland   \n",
       "\n",
       "                                               Top20  \\\n",
       "0                Sara Denver, nurse turned solicitor   \n",
       "1  Burundi peace initiative fades after rebels re...   \n",
       "2                               Corinthians (Brazil)   \n",
       "3  Upending a table, Chopping a line and Scoring ...   \n",
       "4              Blunkett outlines vision for over 11s   \n",
       "\n",
       "                                               Top21  \\\n",
       "0     Diana's landmine crusade put Tories in a panic   \n",
       "1               PE points the way forward to the ECB   \n",
       "2                                 Tony's pet project   \n",
       "3   Scientific evidence 'unreliable', defence claims   \n",
       "4  Embattled Dobson attacks 'play now, pay later'...   \n",
       "\n",
       "                                               Top22  \\\n",
       "0  Yeltsin's resignation caught opposition flat-f...   \n",
       "1  Campaigners keep up pressure on Nazi war crime...   \n",
       "2                            Al Nassr (Saudi Arabia)   \n",
       "3     Fusco wins judicial review in extradition case   \n",
       "4                                  Doom and the Dome   \n",
       "\n",
       "                             Top23  \\\n",
       "0                 Russian roulette   \n",
       "1                   Jane Ratcliffe   \n",
       "2                Ideal Holmes show   \n",
       "3    Rebels thwart Russian advance   \n",
       "4  What is the north-south divide?   \n",
       "\n",
       "                                               Top24  \\\n",
       "0                                           Sold out   \n",
       "1  Yet more things you wouldn't know without the ...   \n",
       "2               Pinochet leaves hospital after tests   \n",
       "3               Blair orders shake-up of failing NHS   \n",
       "4                          Aitken released from jail   \n",
       "\n",
       "                          Top25  \n",
       "0            Recovering a title  \n",
       "1  Millennium bug fails to bite  \n",
       "2                  Useful links  \n",
       "3   Lessons of law's hard heart  \n",
       "4                    Gone aloft  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad77fb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[df['Date'] < '20150101']\n",
    "test =df[df['Date'] > '20141231']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1980f0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing punctuations\n",
    "data = train.iloc[:,2:27]\n",
    "data.replace (\"[^a-zA-Z]\",\" \",regex=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "138cccd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A  hindrance to operations   extracts from the...</td>\n",
       "      <td>Scorecard</td>\n",
       "      <td>Hughes  instant hit buoys Blues</td>\n",
       "      <td>Jack gets his skates on at ice cold Alex</td>\n",
       "      <td>Chaos as Maracana builds up for United</td>\n",
       "      <td>Depleted Leicester prevail as Elliott spoils E...</td>\n",
       "      <td>Hungry Spurs sense rich pickings</td>\n",
       "      <td>Gunners so wide of an easy target</td>\n",
       "      <td>Derby raise a glass to Strupar s debut double</td>\n",
       "      <td>Southgate strikes  Leeds pay the penalty</td>\n",
       "      <td>...</td>\n",
       "      <td>Flintoff injury piles on woe for England</td>\n",
       "      <td>Hunters threaten Jospin with new battle of the...</td>\n",
       "      <td>Kohl s successor drawn into scandal</td>\n",
       "      <td>The difference between men and women</td>\n",
       "      <td>Sara Denver  nurse turned solicitor</td>\n",
       "      <td>Diana s landmine crusade put Tories in a panic</td>\n",
       "      <td>Yeltsin s resignation caught opposition flat f...</td>\n",
       "      <td>Russian roulette</td>\n",
       "      <td>Sold out</td>\n",
       "      <td>Recovering a title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Scorecard</td>\n",
       "      <td>The best lake scene</td>\n",
       "      <td>Leader  German sleaze inquiry</td>\n",
       "      <td>Cheerio  boyo</td>\n",
       "      <td>The main recommendations</td>\n",
       "      <td>Has Cubie killed fees</td>\n",
       "      <td>Has Cubie killed fees</td>\n",
       "      <td>Has Cubie killed fees</td>\n",
       "      <td>Hopkins  furious  at Foster s lack of Hannibal...</td>\n",
       "      <td>Has Cubie killed fees</td>\n",
       "      <td>...</td>\n",
       "      <td>On the critical list</td>\n",
       "      <td>The timing of their lives</td>\n",
       "      <td>Dear doctor</td>\n",
       "      <td>Irish court halts IRA man s extradition to Nor...</td>\n",
       "      <td>Burundi peace initiative fades after rebels re...</td>\n",
       "      <td>PE points the way forward to the ECB</td>\n",
       "      <td>Campaigners keep up pressure on Nazi war crime...</td>\n",
       "      <td>Jane Ratcliffe</td>\n",
       "      <td>Yet more things you wouldn t know without the ...</td>\n",
       "      <td>Millennium bug fails to bite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coventry caught on counter by Flo</td>\n",
       "      <td>United s rivals on the road to Rio</td>\n",
       "      <td>Thatcher issues defence before trial by video</td>\n",
       "      <td>Police help Smith lay down the law at Everton</td>\n",
       "      <td>Tale of Trautmann bears two more retellings</td>\n",
       "      <td>England on the rack</td>\n",
       "      <td>Pakistan retaliate with call for video of Walsh</td>\n",
       "      <td>Cullinan continues his Cape monopoly</td>\n",
       "      <td>McGrath puts India out of their misery</td>\n",
       "      <td>Blair Witch bandwagon rolls on</td>\n",
       "      <td>...</td>\n",
       "      <td>South Melbourne  Australia</td>\n",
       "      <td>Necaxa  Mexico</td>\n",
       "      <td>Real Madrid  Spain</td>\n",
       "      <td>Raja Casablanca  Morocco</td>\n",
       "      <td>Corinthians  Brazil</td>\n",
       "      <td>Tony s pet project</td>\n",
       "      <td>Al Nassr  Saudi Arabia</td>\n",
       "      <td>Ideal Holmes show</td>\n",
       "      <td>Pinochet leaves hospital after tests</td>\n",
       "      <td>Useful links</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pilgrim knows how to progress</td>\n",
       "      <td>Thatcher facing ban</td>\n",
       "      <td>McIlroy calls for Irish fighting spirit</td>\n",
       "      <td>Leicester bin stadium blueprint</td>\n",
       "      <td>United braced for Mexican wave</td>\n",
       "      <td>Auntie back in fashion  even if the dress look...</td>\n",
       "      <td>Shoaib appeal goes to the top</td>\n",
       "      <td>Hussain hurt by  shambles  but lays blame on e...</td>\n",
       "      <td>England s decade of disasters</td>\n",
       "      <td>Revenge is sweet for jubilant Cronje</td>\n",
       "      <td>...</td>\n",
       "      <td>Putin admits Yeltsin quit to give him a head s...</td>\n",
       "      <td>BBC worst hit as digital TV begins to bite</td>\n",
       "      <td>How much can you pay for</td>\n",
       "      <td>Christmas glitches</td>\n",
       "      <td>Upending a table  Chopping a line and Scoring ...</td>\n",
       "      <td>Scientific evidence  unreliable   defence claims</td>\n",
       "      <td>Fusco wins judicial review in extradition case</td>\n",
       "      <td>Rebels thwart Russian advance</td>\n",
       "      <td>Blair orders shake up of failing NHS</td>\n",
       "      <td>Lessons of law s hard heart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hitches and Horlocks</td>\n",
       "      <td>Beckham off but United survive</td>\n",
       "      <td>Breast cancer screening</td>\n",
       "      <td>Alan Parker</td>\n",
       "      <td>Guardian readers  are you all whingers</td>\n",
       "      <td>Hollywood Beyond</td>\n",
       "      <td>Ashes and diamonds</td>\n",
       "      <td>Whingers   a formidable minority</td>\n",
       "      <td>Alan Parker   part two</td>\n",
       "      <td>Thuggery  Toxins and Ties</td>\n",
       "      <td>...</td>\n",
       "      <td>Most everywhere   UDIs</td>\n",
       "      <td>Most wanted   Chloe lunettes</td>\n",
       "      <td>Return of the cane  completely off the agenda</td>\n",
       "      <td>From Sleepy Hollow to Greeneland</td>\n",
       "      <td>Blunkett outlines vision for over   s</td>\n",
       "      <td>Embattled Dobson attacks  play now  pay later ...</td>\n",
       "      <td>Doom and the Dome</td>\n",
       "      <td>What is the north south divide</td>\n",
       "      <td>Aitken released from jail</td>\n",
       "      <td>Gone aloft</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  A  hindrance to operations   extracts from the...   \n",
       "1                                          Scorecard   \n",
       "2                  Coventry caught on counter by Flo   \n",
       "3                      Pilgrim knows how to progress   \n",
       "4                               Hitches and Horlocks   \n",
       "\n",
       "                                    1  \\\n",
       "0                           Scorecard   \n",
       "1                 The best lake scene   \n",
       "2  United s rivals on the road to Rio   \n",
       "3                 Thatcher facing ban   \n",
       "4      Beckham off but United survive   \n",
       "\n",
       "                                               2  \\\n",
       "0                Hughes  instant hit buoys Blues   \n",
       "1                  Leader  German sleaze inquiry   \n",
       "2  Thatcher issues defence before trial by video   \n",
       "3        McIlroy calls for Irish fighting spirit   \n",
       "4                        Breast cancer screening   \n",
       "\n",
       "                                               3  \\\n",
       "0       Jack gets his skates on at ice cold Alex   \n",
       "1                                  Cheerio  boyo   \n",
       "2  Police help Smith lay down the law at Everton   \n",
       "3                Leicester bin stadium blueprint   \n",
       "4                                    Alan Parker   \n",
       "\n",
       "                                             4  \\\n",
       "0       Chaos as Maracana builds up for United   \n",
       "1                     The main recommendations   \n",
       "2  Tale of Trautmann bears two more retellings   \n",
       "3               United braced for Mexican wave   \n",
       "4      Guardian readers  are you all whingers    \n",
       "\n",
       "                                                   5  \\\n",
       "0  Depleted Leicester prevail as Elliott spoils E...   \n",
       "1                             Has Cubie killed fees    \n",
       "2                                England on the rack   \n",
       "3  Auntie back in fashion  even if the dress look...   \n",
       "4                                   Hollywood Beyond   \n",
       "\n",
       "                                                 6  \\\n",
       "0                 Hungry Spurs sense rich pickings   \n",
       "1                           Has Cubie killed fees    \n",
       "2  Pakistan retaliate with call for video of Walsh   \n",
       "3                    Shoaib appeal goes to the top   \n",
       "4                               Ashes and diamonds   \n",
       "\n",
       "                                                   7  \\\n",
       "0                  Gunners so wide of an easy target   \n",
       "1                             Has Cubie killed fees    \n",
       "2               Cullinan continues his Cape monopoly   \n",
       "3  Hussain hurt by  shambles  but lays blame on e...   \n",
       "4                   Whingers   a formidable minority   \n",
       "\n",
       "                                                   8  \\\n",
       "0      Derby raise a glass to Strupar s debut double   \n",
       "1  Hopkins  furious  at Foster s lack of Hannibal...   \n",
       "2             McGrath puts India out of their misery   \n",
       "3                      England s decade of disasters   \n",
       "4                             Alan Parker   part two   \n",
       "\n",
       "                                          9  ...  \\\n",
       "0  Southgate strikes  Leeds pay the penalty  ...   \n",
       "1                    Has Cubie killed fees   ...   \n",
       "2            Blair Witch bandwagon rolls on  ...   \n",
       "3      Revenge is sweet for jubilant Cronje  ...   \n",
       "4                 Thuggery  Toxins and Ties  ...   \n",
       "\n",
       "                                                  15  \\\n",
       "0           Flintoff injury piles on woe for England   \n",
       "1                               On the critical list   \n",
       "2                        South Melbourne  Australia    \n",
       "3  Putin admits Yeltsin quit to give him a head s...   \n",
       "4                             Most everywhere   UDIs   \n",
       "\n",
       "                                                  16  \\\n",
       "0  Hunters threaten Jospin with new battle of the...   \n",
       "1                          The timing of their lives   \n",
       "2                                    Necaxa  Mexico    \n",
       "3         BBC worst hit as digital TV begins to bite   \n",
       "4                       Most wanted   Chloe lunettes   \n",
       "\n",
       "                                               17  \\\n",
       "0             Kohl s successor drawn into scandal   \n",
       "1                                     Dear doctor   \n",
       "2                             Real Madrid  Spain    \n",
       "3                     How much can you pay for      \n",
       "4  Return of the cane  completely off the agenda    \n",
       "\n",
       "                                                  18  \\\n",
       "0               The difference between men and women   \n",
       "1  Irish court halts IRA man s extradition to Nor...   \n",
       "2                          Raja Casablanca  Morocco    \n",
       "3                                 Christmas glitches   \n",
       "4                   From Sleepy Hollow to Greeneland   \n",
       "\n",
       "                                                  19  \\\n",
       "0                Sara Denver  nurse turned solicitor   \n",
       "1  Burundi peace initiative fades after rebels re...   \n",
       "2                               Corinthians  Brazil    \n",
       "3  Upending a table  Chopping a line and Scoring ...   \n",
       "4              Blunkett outlines vision for over   s   \n",
       "\n",
       "                                                  20  \\\n",
       "0     Diana s landmine crusade put Tories in a panic   \n",
       "1               PE points the way forward to the ECB   \n",
       "2                                 Tony s pet project   \n",
       "3   Scientific evidence  unreliable   defence claims   \n",
       "4  Embattled Dobson attacks  play now  pay later ...   \n",
       "\n",
       "                                                  21  \\\n",
       "0  Yeltsin s resignation caught opposition flat f...   \n",
       "1  Campaigners keep up pressure on Nazi war crime...   \n",
       "2                            Al Nassr  Saudi Arabia    \n",
       "3     Fusco wins judicial review in extradition case   \n",
       "4                                  Doom and the Dome   \n",
       "\n",
       "                                22  \\\n",
       "0                 Russian roulette   \n",
       "1                   Jane Ratcliffe   \n",
       "2                Ideal Holmes show   \n",
       "3    Rebels thwart Russian advance   \n",
       "4  What is the north south divide    \n",
       "\n",
       "                                                  23  \\\n",
       "0                                           Sold out   \n",
       "1  Yet more things you wouldn t know without the ...   \n",
       "2               Pinochet leaves hospital after tests   \n",
       "3               Blair orders shake up of failing NHS   \n",
       "4                          Aitken released from jail   \n",
       "\n",
       "                             24  \n",
       "0            Recovering a title  \n",
       "1  Millennium bug fails to bite  \n",
       "2                  Useful links  \n",
       "3   Lessons of law s hard heart  \n",
       "4                    Gone aloft  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#renaming column for ease of access\n",
    "list1=[i for i in range(25)]\n",
    "new_Index = [str(i) for i in list1]\n",
    "data.columns = new_Index\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8fb1a72",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_Index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-dd7574e44e0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#converting into lowercase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnew_Index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'new_Index' is not defined"
     ]
    }
   ],
   "source": [
    "#converting into lowercase\n",
    "for index in new_Index:\n",
    "    data[index] = data[index].str.lower()\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f48c5d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Flesh eating zombie crisis  Sorted Getting a better salary Byers stirs row over cheap car imports Come the revolution Cosi Fan Tutte Crashes turn Cahoot launch into a disaster A tasty blend Coldplay Byers sends Bupa hospitals takeover to watchdog Work in progress Lynden David Hall AOL signs deal with mobile retailer Luck but few ideas on side of Holland The Odds Fellow Slow off the blocks Red devils have the best tunes Portugal s beautiful ones find hard edge to match their brilliance Defeat is not an option Evergreen Hagi still flourishing Euro      Shorts Euro      Diary Bierhoff claims final belief Adams stirred by spirit of Harry and St George Abstinence and the opposite of sexy football England       Portugal'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(str(x) for x in data.iloc[110,0:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1a18a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines=[]\n",
    "for rows in range(0,len(data.index)):\n",
    "    headlines.append(' '.join(str(x) for x in data.iloc[rows,0:25]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7865e76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fifth round draw BBC unveils secret weapon in ratings war  South Melbourne Second Division round up European round up Third Division round up Welfare could claim Killie tie as Caley Thistle land Celtic Ferguson puts brave face on Rio meltdown Southgate in striking form to pre empt penalties Second bite for Wolves Scallywags have Chelsea looking to the bench England miss a trick for Centurion Radio just in time for England batting collapse Faith in the future Youth at the helm until it goes under United stave off inevitable Time Warner and AOL to merge Keep up Waging global war Desktop icons  No    The Qwerty keyboard The sec s files The low down  Workplace bullying Met  not equipped  to solve murders Tranmere tie will not be replayed Rebel attacks take toll on Russia Met lent stopped car to Lawrence'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9aaa4b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "054af1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement BAG OF WORDS\n",
    "countervector = CountVectorizer(ngram_range=(2,2))\n",
    "traindataset=countervector.fit_transform(headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0dd7c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=200)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#implement RandomForest Classifier\n",
    "randomclassifier=RandomForestClassifier(n_estimators=200,criterion='entropy')\n",
    "randomclassifier.fit(traindataset,train['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fcf4ccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictin for the test Dataset\n",
    "test_transform=[]\n",
    "for row in range(0,len(test.index)):\n",
    "    test_transform.append(' '.join(str(x) for x in test.iloc[row,2:27]))\n",
    "test_dataset = countervector.transform(test_transform)\n",
    "predictions=randomclassifier.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "432e5d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import library to check accurracy\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bc0749c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion metrics -- > \n",
      "[[135  51]\n",
      " [ 10 182]]\n",
      "\n",
      "accuracy socre -- >\n",
      " 0.8386243386243386\n",
      "\n",
      "classification report -- >\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.73      0.82       186\n",
      "           1       0.78      0.95      0.86       192\n",
      "\n",
      "    accuracy                           0.84       378\n",
      "   macro avg       0.86      0.84      0.84       378\n",
      "weighted avg       0.85      0.84      0.84       378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"confusion metrics -- > \\n{confusion_matrix(test['Label'],predictions)}\\n\")\n",
    "print(f\"accuracy socre -- >\\n {accuracy_score(test['Label'],predictions)}\\n\")\n",
    "print(f\"classification report -- >\\n { classification_report(test['Label'],predictions)}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a3a1e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d7df6a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a0d2825f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement BAG OF WORDS\n",
    "tfidfvector = TfidfVectorizer(ngram_range=(2,2))\n",
    "traindataset= tfidfvector.fit_transform(headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6447180c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=200)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#implement RandomForest Classifier\n",
    "randomclassifier=RandomForestClassifier(n_estimators=200,criterion='entropy')\n",
    "randomclassifier.fit(traindataset,train['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "23f44d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictin for the test Dataset\n",
    "test_transform=[]\n",
    "for row in range(0,len(test.index)):\n",
    "    test_transform.append(' '.join(str(x) for x in test.iloc[row,2:27]))\n",
    "test_dataset = tfidfvector.transform(test_transform)\n",
    "predictions=randomclassifier.predict(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "866b8d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion metrics -- > \n",
      "[[144  42]\n",
      " [ 13 179]]\n",
      "\n",
      "accuracy socre -- >\n",
      " 0.8544973544973545\n",
      "\n",
      "classification report -- >\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.77      0.84       186\n",
      "           1       0.81      0.93      0.87       192\n",
      "\n",
      "    accuracy                           0.85       378\n",
      "   macro avg       0.86      0.85      0.85       378\n",
      "weighted avg       0.86      0.85      0.85       378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"confusion metrics -- > \\n{confusion_matrix(test['Label'],predictions)}\\n\")\n",
    "print(f\"accuracy socre -- >\\n {accuracy_score(test['Label'],predictions)}\\n\")\n",
    "print(f\"classification report -- >\\n { classification_report(test['Label'],predictions)}\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22196d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07365b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "navie = MultinomialNB()\n",
    "navie.fit(traindataset,train['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a407f681",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictin for the test Dataset\n",
    "test_transform=[]\n",
    "for row in range(0,len(test.index)):\n",
    "    test_transform.append(' '.join(str(x) for x in test.iloc[row,2:27]))\n",
    "test_dataset = countervector.transform(test_transform)\n",
    "predictions=navie.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adc83fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion metrics -- > \n",
      "[[138  48]\n",
      " [ 10 182]]\n",
      "\n",
      "accuracy socre -- >\n",
      " 0.8465608465608465\n",
      "\n",
      "classification report -- >\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.74      0.83       186\n",
      "           1       0.79      0.95      0.86       192\n",
      "\n",
      "    accuracy                           0.85       378\n",
      "   macro avg       0.86      0.84      0.84       378\n",
      "weighted avg       0.86      0.85      0.84       378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"confusion metrics -- > \\n{confusion_matrix(test['Label'],predictions)}\\n\")\n",
    "print(f\"accuracy socre -- >\\n {accuracy_score(test['Label'],predictions)}\\n\")\n",
    "print(f\"classification report -- >\\n { classification_report(test['Label'],predictions)}\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d986726",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "47bea633",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9dc9160e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:35:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg.fit(traindataset,train['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f2c72ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictin for the test Dataset\n",
    "test_transform=[]\n",
    "for row in range(0,len(test.index)):\n",
    "    test_transform.append(' '.join(str(x) for x in test.iloc[row,2:27]))\n",
    "test_dataset = countervector.transform(test_transform)\n",
    "predictions=xg.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "74e38fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion metrics -- > \n",
      "[[150  36]\n",
      " [ 36 156]]\n",
      "\n",
      "accuracy socre -- >\n",
      " 0.8095238095238095\n",
      "\n",
      "classification report -- >\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81       186\n",
      "           1       0.81      0.81      0.81       192\n",
      "\n",
      "    accuracy                           0.81       378\n",
      "   macro avg       0.81      0.81      0.81       378\n",
      "weighted avg       0.81      0.81      0.81       378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"confusion metrics -- > \\n{confusion_matrix(test['Label'],predictions)}\\n\")\n",
    "print(f\"accuracy socre -- >\\n {accuracy_score(test['Label'],predictions)}\\n\")\n",
    "print(f\"classification report -- >\\n { classification_report(test['Label'],predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "23c4d969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement BAG OF WORDS\n",
    "tfidfvector = TfidfVectorizer(ngram_range=(2,2))\n",
    "traindataset= tfidfvector.fit_transform(headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c854a42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:39:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg.fit(traindataset,train['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c3a1204",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictin for the test Dataset\n",
    "test_transform=[]\n",
    "for row in range(0,len(test.index)):\n",
    "    test_transform.append(' '.join(str(x) for x in test.iloc[row,2:27]))\n",
    "test_dataset = tfidfvector.transform(test_transform)\n",
    "predictions=xg.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f083b22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion metrics -- > \n",
      "[[148  38]\n",
      " [ 31 161]]\n",
      "\n",
      "accuracy socre -- >\n",
      " 0.8174603174603174\n",
      "\n",
      "classification report -- >\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81       186\n",
      "           1       0.81      0.84      0.82       192\n",
      "\n",
      "    accuracy                           0.82       378\n",
      "   macro avg       0.82      0.82      0.82       378\n",
      "weighted avg       0.82      0.82      0.82       378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"confusion metrics -- > \\n{confusion_matrix(test['Label'],predictions)}\\n\")\n",
    "print(f\"accuracy socre -- >\\n {accuracy_score(test['Label'],predictions)}\\n\")\n",
    "print(f\"classification report -- >\\n { classification_report(test['Label'],predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e83b6e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5b7f401a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = CatBoostClassifier(\n",
    "    iterations=15, \n",
    "    learning_rate=0.1, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f287de21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6921981\ttotal: 44.8s\tremaining: 10m 26s\n",
      "1:\tlearn: 0.6915045\ttotal: 52.3s\tremaining: 5m 39s\n",
      "2:\tlearn: 0.6907619\ttotal: 55.2s\tremaining: 3m 40s\n",
      "3:\tlearn: 0.6898112\ttotal: 58.2s\tremaining: 2m 39s\n",
      "4:\tlearn: 0.6890156\ttotal: 1m 1s\tremaining: 2m 2s\n",
      "5:\tlearn: 0.6879038\ttotal: 1m 5s\tremaining: 1m 37s\n",
      "6:\tlearn: 0.6871814\ttotal: 1m 9s\tremaining: 1m 19s\n",
      "7:\tlearn: 0.6867444\ttotal: 1m 13s\tremaining: 1m 4s\n",
      "8:\tlearn: 0.6860562\ttotal: 1m 16s\tremaining: 51s\n",
      "9:\tlearn: 0.6854795\ttotal: 1m 19s\tremaining: 39.8s\n",
      "10:\tlearn: 0.6846092\ttotal: 1m 22s\tremaining: 30s\n",
      "11:\tlearn: 0.6840251\ttotal: 1m 25s\tremaining: 21.4s\n",
      "12:\tlearn: 0.6829016\ttotal: 1m 28s\tremaining: 13.6s\n",
      "13:\tlearn: 0.6816911\ttotal: 1m 31s\tremaining: 6.55s\n",
      "14:\tlearn: 0.6807662\ttotal: 1m 35s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x2136e595b20>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(traindataset,train['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5b5ff15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictin for the test Dataset\n",
    "test_transform=[]\n",
    "for row in range(0,len(test.index)):\n",
    "    test_transform.append(' '.join(str(x) for x in test.iloc[row,2:27]))\n",
    "test_dataset = tfidfvector.transform(test_transform)\n",
    "predictions=clf.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "59ab8cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion metrics -- > \n",
      "[[ 23 163]\n",
      " [  9 183]]\n",
      "\n",
      "accuracy socre -- >\n",
      " 0.544973544973545\n",
      "\n",
      "classification report -- >\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.12      0.21       186\n",
      "           1       0.53      0.95      0.68       192\n",
      "\n",
      "    accuracy                           0.54       378\n",
      "   macro avg       0.62      0.54      0.45       378\n",
      "weighted avg       0.62      0.54      0.45       378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"confusion metrics -- > \\n{confusion_matrix(test['Label'],predictions)}\\n\")\n",
    "print(f\"accuracy socre -- >\\n {accuracy_score(test['Label'],predictions)}\\n\")\n",
    "print(f\"classification report -- >\\n { classification_report(test['Label'],predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ab80c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4ba5aff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b4ec312c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ber = BernoulliNB()\n",
    "ber.fit(traindataset,train['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5e9464bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictin for the test Dataset\n",
    "test_transform=[]\n",
    "for row in range(0,len(test.index)):\n",
    "    test_transform.append(' '.join(str(x) for x in test.iloc[row,2:27]))\n",
    "test_dataset = tfidfvector.transform(test_transform)\n",
    "predictions=ber.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "83207676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion metrics -- > \n",
      "[[130  56]\n",
      " [  0 192]]\n",
      "\n",
      "accuracy socre -- >\n",
      " 0.8518518518518519\n",
      "\n",
      "classification report -- >\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.70      0.82       186\n",
      "           1       0.77      1.00      0.87       192\n",
      "\n",
      "    accuracy                           0.85       378\n",
      "   macro avg       0.89      0.85      0.85       378\n",
      "weighted avg       0.89      0.85      0.85       378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"confusion metrics -- > \\n{confusion_matrix(test['Label'],predictions)}\\n\")\n",
    "print(f\"accuracy socre -- >\\n {accuracy_score(test['Label'],predictions)}\\n\")\n",
    "print(f\"classification report -- >\\n { classification_report(test['Label'],predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a4dbe9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "11ce1ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = CategoricalNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dba661bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-f8db91dfc073>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraindataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1164\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1165\u001b[0m         \"\"\"\n\u001b[1;32m-> 1166\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    610\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m         \"\"\"\n\u001b[1;32m--> 612\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    613\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1221\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1222\u001b[1;33m         X, y = self._validate_data(X, y, dtype='int', accept_sparse=False,\n\u001b[0m\u001b[0;32m   1223\u001b[0m                                    force_all_finite=True)\n\u001b[0;32m   1224\u001b[0m         \u001b[0mcheck_non_negative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"CategoricalNB (input X)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    812\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    815\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    591\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0m_ensure_no_complex_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         array = _ensure_sparse_format(array, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    594\u001b[0m                                       \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m                                       \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_ensure_sparse_format\u001b[1;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maccept_sparse\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m         raise TypeError('A sparse matrix was passed, but dense '\n\u001b[0m\u001b[0;32m    361\u001b[0m                         \u001b[1;34m'data is required. Use X.toarray() to '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m                         'convert to a dense numpy array.')\n",
      "\u001b[1;31mTypeError\u001b[0m: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array."
     ]
    }
   ],
   "source": [
    "cat.fit(traindataset,train['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "52da602d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This CategoricalNB instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-8278d242c257>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtest_transform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m27\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcountervector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_transform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mpredictions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \"\"\"\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mjll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1039\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1041\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1042\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This CategoricalNB instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "#predictin for the test Dataset\n",
    "test_transform=[]\n",
    "for row in range(0,len(test.index)):\n",
    "    test_transform.append(' '.join(str(x) for x in test.iloc[row,2:27]))\n",
    "test_dataset = countervector.transform(test_transform)\n",
    "predictions=cat.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "926382a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## random forest\n",
    "countervector = CountVectorizer(ngram_range=(5,5))\n",
    "traindataset1=countervector.fit_transform(headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1fbdca60",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvector = TfidfVectorizer(ngram_range=(5,5))\n",
    "traindataset2= tfidfvector.fit_transform(headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "90bd7d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=350, n_jobs=-1)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomclassifier1=RandomForestClassifier(n_estimators=350,criterion='entropy',n_jobs=-1)\n",
    "randomclassifier1.fit(traindataset1,train['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "536665c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=350, n_jobs=-1)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomclassifier2=RandomForestClassifier(n_estimators=350,criterion='entropy',n_jobs=-1)\n",
    "randomclassifier2.fit(traindataset2,train['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "063cfc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform=[]\n",
    "for row in range(0,len(test.index)):\n",
    "    test_transform.append(' '.join(str(x) for x in test.iloc[row,2:27]))\n",
    "test_dataset = countervector.transform(test_transform)\n",
    "predictions1=randomclassifier1.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d78cb0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform=[]\n",
    "for row in range(0,len(test.index)):\n",
    "    test_transform.append(' '.join(str(x) for x in test.iloc[row,2:27]))\n",
    "test_dataset = tfidfvector.transform(test_transform)\n",
    "predictions2=randomclassifier2.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c33b4628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** with counter vector\n",
      "confusion metrics -- > \n",
      "[[122  64]\n",
      " [  1 191]]\n",
      "\n",
      "accuracy socre -- >\n",
      " 0.828042328042328\n",
      "\n",
      "classification report -- >\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.66      0.79       186\n",
      "           1       0.75      0.99      0.85       192\n",
      "\n",
      "    accuracy                           0.83       378\n",
      "   macro avg       0.87      0.83      0.82       378\n",
      "weighted avg       0.87      0.83      0.82       378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('***** with counter vector')\n",
    "print(f\"confusion metrics -- > \\n{confusion_matrix(test['Label'],predictions1)}\\n\")\n",
    "print(f\"accuracy socre -- >\\n {accuracy_score(test['Label'],predictions1)}\\n\")\n",
    "print(f\"classification report -- >\\n { classification_report(test['Label'],predictions1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f9e659fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** with TDIF vector\n",
      "confusion metrics -- > \n",
      "[[125  61]\n",
      " [  1 191]]\n",
      "\n",
      "accuracy socre -- >\n",
      " 0.8359788359788359\n",
      "\n",
      "classification report -- >\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.67      0.80       186\n",
      "           1       0.76      0.99      0.86       192\n",
      "\n",
      "    accuracy                           0.84       378\n",
      "   macro avg       0.88      0.83      0.83       378\n",
      "weighted avg       0.87      0.84      0.83       378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('***** with TDIF vector')\n",
    "print(f\"confusion metrics -- > \\n{confusion_matrix(test['Label'],predictions2)}\\n\")\n",
    "print(f\"accuracy socre -- >\\n {accuracy_score(test['Label'],predictions2)}\\n\")\n",
    "print(f\"classification report -- >\\n { classification_report(test['Label'],predictions2)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
